{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle House Price Prob.\n",
    "\n",
    "\n",
    "\n",
    "2018.10.20.Sat. By Taeu\n",
    "\n",
    "for Google Machine learning study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "\n",
    "# Content\n",
    "## 1. Data Skimming\n",
    "\n",
    "    1-1. Data collect\n",
    "    1-2. Data load\n",
    "    1-3. Data Skimming ( to excel _ )\n",
    "\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "    2-1. Fill NAs\n",
    "    2-2. Drop\n",
    "    2-3. Editing ( Adding, Editing, Binning etc..)\n",
    "    \n",
    "    \n",
    "## 3. Model & Evaluation\n",
    "\n",
    "    3-1 pipeline\n",
    "    3-2 Model Selection & Eval\n",
    "    3-3 Result - Submission\n",
    "    \n",
    "    \n",
    "*******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# install xgboost\\nhttp://cleancode-ws.tistory.com/79\\n# understanding xgboost\\nhttps://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#from xgboost import XGBRegressor\n",
    "# if you want to use XGBoost\n",
    "'''\n",
    "# install xgboost\n",
    "http://cleancode-ws.tistory.com/79\n",
    "# understanding xgboost\n",
    "https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Skimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-3. data skimming"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data들을 시각화하는 것보다 한 가지의 col, feature에 대한 이해가 중요하다.\n",
    "\n",
    "2. Data Preprocessing , Feature Engineering\n",
    "- 2-1. NA 값 처리 (결측값처리)\n",
    "- 2-2. Type 변경\n",
    "- 2-3. Categorical 변수들 재정의\n",
    "등을 하기 위해 각 feature가 어떤 의미를 가지는지, 어떤 값이 있는지, 결측지는 있는지, 데이터 타입이 무엇인지를 파악할 필요가있다.\n",
    "\n",
    "일련의 과정들을 하나씩 살펴보면서 2번에 필요한 사항들을 메모하기 위해 엑셀에 따로 값들을 불러놓고 체크하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns\n",
    "nulls = full.isnull().sum()\n",
    "nulls = nulls[nulls>0]\n",
    "nulls_index = nulls.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacols = []\n",
    "datanull = []\n",
    "datatype = []\n",
    "datavalue = []\n",
    "\n",
    "for col in cols:\n",
    "    datacols += [col]\n",
    "    datatype += [train[col].dtype]\n",
    "    datavalue+= [train[col][0]]\n",
    "    if col in nulls_index :\n",
    "        datanull += [nulls[col]]\n",
    "    else :\n",
    "        datanull += [0]\n",
    "        \n",
    "idd = list(range(cols.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make checklist of cols(features)\n",
    "pd.DataFrame({'num': idd, 'columns': datacols, 'datanull':datanull ,'datavalue':datavalue,\n",
    "              'datatype': datatype }).to_csv('hp_columns_info.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Missing Value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "결측치를 채우는 과정은 다양하다. \n",
    "\n",
    "(1) 0이나 'None'값으로 채운다.\n",
    "(2) 최빈값 사용. (mode 나 median()등을 이용)\n",
    "(3) 비슷한 자료들끼리 묶어서 비슷한 값을 유추하는 방법. (or clustering algorithms 이용)\n",
    "\n",
    "위 중 하나를 선택하기 위해서는 feature의 정확한 이해가 필요하다.\n",
    "그 중에서 LotFrontAge의 결측값을 다른 변수들간의 관계를 먼저 파악하고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">LotFrontage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotAreaCut</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(1299.999, 4922.4]</th>\n",
       "      <td>35.741036</td>\n",
       "      <td>34.0</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4922.4, 7007.6]</th>\n",
       "      <td>55.460674</td>\n",
       "      <td>52.0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(7007.6, 7960.4]</th>\n",
       "      <td>63.008000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(7960.4, 8741.0]</th>\n",
       "      <td>66.964844</td>\n",
       "      <td>65.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(8741.0, 9453.0]</th>\n",
       "      <td>70.106996</td>\n",
       "      <td>70.0</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(9453.0, 10151.6]</th>\n",
       "      <td>73.972656</td>\n",
       "      <td>75.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10151.6, 11001.2]</th>\n",
       "      <td>73.650794</td>\n",
       "      <td>75.0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(11001.2, 12203.8]</th>\n",
       "      <td>83.377193</td>\n",
       "      <td>82.0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(12203.8, 14300.6]</th>\n",
       "      <td>84.991228</td>\n",
       "      <td>85.0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(14300.6, 215245.0]</th>\n",
       "      <td>94.188119</td>\n",
       "      <td>90.0</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LotFrontage             \n",
       "                           mean median count\n",
       "LotAreaCut                                  \n",
       "(1299.999, 4922.4]    35.741036   34.0   251\n",
       "(4922.4, 7007.6]      55.460674   52.0   267\n",
       "(7007.6, 7960.4]      63.008000   62.0   250\n",
       "(7960.4, 8741.0]      66.964844   65.0   256\n",
       "(8741.0, 9453.0]      70.106996   70.0   243\n",
       "(9453.0, 10151.6]     73.972656   75.0   256\n",
       "(10151.6, 11001.2]    73.650794   75.0   252\n",
       "(11001.2, 12203.8]    83.377193   82.0   228\n",
       "(12203.8, 14300.6]    84.991228   85.0   228\n",
       "(14300.6, 215245.0]   94.188119   90.0   202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])\n",
    "\n",
    "full['LotAreaCut']= pd.qcut(full.LotArea,10)\n",
    "\n",
    "full.groupby(['LotAreaCut'])[['LotFrontage']].agg(['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['LotFrontage'] = full.groupby(['LotAreaCut','Neighborhood'])['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "full['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 변수들은 다 0 이나 None 값으로\n",
    "# nulls_index = nulls.index\n",
    "\n",
    "for col in nulls_index:\n",
    "    na_value = 0\n",
    "    if full[col].dtype == object :\n",
    "        na_value = \"None\"\n",
    "    full[col].fillna(na_value, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it's done\n",
    "a = full.isnull().sum()\n",
    "a[a>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = ['SalePrice','Id']\n",
    "for var in drop_index:\n",
    "    full.drop([var],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) type 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_col = full.columns\n",
    "for var in full_col:\n",
    "    if full[var].dtype == object :\n",
    "        full[var] = full[var].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ['GarageYrBlt','YearBuilt','YearRemodAdd','MoSold','YrSold']\n",
    "categorical = ['MSSubClass','OverallQual','OverallCond',]\n",
    "strtype = time + categorical\n",
    "for var in strtype:\n",
    "    full[var] = full[var].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(full['LotAreaCut'][0])\n",
    "full['LotAreaCut'] = full['LotAreaCut'].astype(str)\n",
    "full.drop('LotAreaCut',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float 변경은 scale 조정에서 float로 바뀌므로 생략\n",
    "full_col = full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric 변수들 모음\n",
    "numeric_col = []\n",
    "for var in full_col:\n",
    "    if type(full[var][0]) != str:\n",
    "        numeric_col += [var]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# ~.fit(data), ~.fit_transform()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "standard = StandardScaler()\n",
    "robust = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 scale을 따로 적용하기 위해서 full의 copy version을 만든다.\n",
    "full1 = full.copy()\n",
    "full2 = full.copy()\n",
    "full3 = full.copy()\n",
    "full4 = full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full1 은 no scale\n",
    "full2[numeric_col] = minmax.fit_transform(full2[numeric_col])\n",
    "full3[numeric_col] = standard.fit_transform(full3[numeric_col])\n",
    "full4[numeric_col] = robust.fit_transform(full4[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch     ...      \\\n",
       "0           1.0           0.0      150.0              0     ...       \n",
       "1           0.0           1.0      284.0              0     ...       \n",
       "2           1.0           0.0      434.0              0     ...       \n",
       "\n",
       "   LotFrontage  LowQualFinSF  MasVnrArea  MiscVal  OpenPorchSF  PoolArea  \\\n",
       "0         65.0             0       196.0        0           61         0   \n",
       "1         80.0             0         0.0        0            0         0   \n",
       "2         68.0             0       162.0        0           42         0   \n",
       "\n",
       "   ScreenPorch  TotRmsAbvGrd  TotalBsmtSF  WoodDeckSF  \n",
       "0            0             8        856.0           0  \n",
       "1            0             6       1262.0         298  \n",
       "2            0             6        920.0           0  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full1[numeric_col].head(3) # full1, full2, full3, full4 들을 확인해보면 다 다른 값들을 가지고 있음\n",
    "#full1은 numeric형을 float로 바꿔줄 필요가있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in numeric_col:\n",
    "    full1[var] = full1[var].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) categorical 변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185224.811567</td>\n",
       "      <td>159250.0</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>95829.724638</td>\n",
       "      <td>99900.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>156125.000000</td>\n",
       "      <td>142500.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>108591.666667</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>143302.972222</td>\n",
       "      <td>132000.0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>239948.501672</td>\n",
       "      <td>215200.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>166772.416667</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>192437.500000</td>\n",
       "      <td>163500.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>169736.551724</td>\n",
       "      <td>166500.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>147810.000000</td>\n",
       "      <td>140750.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>133541.076923</td>\n",
       "      <td>135980.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>200779.080460</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>138647.380952</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>102300.000000</td>\n",
       "      <td>88500.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>129613.333333</td>\n",
       "      <td>128250.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SalePrice                \n",
       "                     mean    median count\n",
       "MSSubClass                               \n",
       "20          185224.811567  159250.0   536\n",
       "30           95829.724638   99900.0    69\n",
       "40          156125.000000  142500.0     4\n",
       "45          108591.666667  107500.0    12\n",
       "50          143302.972222  132000.0   144\n",
       "60          239948.501672  215200.0   299\n",
       "70          166772.416667  156000.0    60\n",
       "75          192437.500000  163500.0    16\n",
       "80          169736.551724  166500.0    58\n",
       "85          147810.000000  140750.0    20\n",
       "90          133541.076923  135980.0    52\n",
       "120         200779.080460  192000.0    87\n",
       "150                   NaN       NaN     0\n",
       "160         138647.380952  146000.0    63\n",
       "180         102300.000000   88500.0    10\n",
       "190         129613.333333  128250.0    30"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.groupby(['MSSubClass'])[['SalePrice']].agg(['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full2[\"oMSSubClass\"] = full2.MSSubClass.map({'180':1, \n",
    "                                    '30':2, '45':2, \n",
    "                                    '190':3, '50':3, '90':3, \n",
    "                                    '85':4, '40':4, '160':4, \n",
    "                                    '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                    '120': 6, '60':6})\n",
    "full3[\"oMSSubClass\"] = full3.MSSubClass.map({'180':1, \n",
    "                                    '30':2, '45':2, \n",
    "                                    '190':3, '50':3, '90':3, \n",
    "                                    '85':4, '40':4, '160':4, \n",
    "                                    '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                    '120': 6, '60':6})\n",
    "full4[\"oMSSubClass\"] = full4.MSSubClass.map({'180':1, \n",
    "                                    '30':2, '45':2, \n",
    "                                    '190':3, '50':3, '90':3, \n",
    "                                    '85':4, '40':4, '160':4, \n",
    "                                    '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                    '120': 6, '60':6})\n",
    "\n",
    "# 해주고 scale 변환을 위해 위의 scale 코드 재실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수 설정\n",
    "def map_values(full):\n",
    "    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n",
    "                                        '30':2, '45':2, \n",
    "                                        '190':3, '50':3, '90':3, \n",
    "                                        '85':4, '40':4, '160':4, \n",
    "                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                        '120': 6, '60':6})\n",
    "    \n",
    "    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n",
    "                                               'IDOTRR':2, 'BrDale':2,\n",
    "                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n",
    "                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n",
    "                                               'NPkVill':5, 'Mitchel':5,\n",
    "                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n",
    "                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n",
    "                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n",
    "                                               'StoneBr':9,\n",
    "                                               'NoRidge':10, 'NridgHt':10})\n",
    "    \n",
    "    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n",
    "    \n",
    "    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n",
    "                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n",
    "                                           '1Story':3, 'SLvl':3,\n",
    "                                           '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n",
    "                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n",
    "                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n",
    "                                             'BrkFace':4, 'Plywood':4,\n",
    "                                             'VinylSd':5,\n",
    "                                             'CemntBd':6,\n",
    "                                             'Stone':7, 'ImStucc':7})\n",
    "    \n",
    "    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n",
    "    \n",
    "    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n",
    "                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n",
    "                                           'Wood':3, 'PConc':4})\n",
    "    \n",
    "    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n",
    "    \n",
    "    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n",
    "    \n",
    "    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n",
    "    \n",
    "    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                           'Detchd':2,\n",
    "                                           '2Types':3, 'Basment':3,\n",
    "                                           'Attchd':4, 'BuiltIn':5})\n",
    "    \n",
    "    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n",
    "    \n",
    "    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n",
    "                                       'CWD':2, 'Con':3, 'New':3})\n",
    "    \n",
    "    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n",
    "                \n",
    "                        \n",
    "                        \n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string -> one_hot_encoding\n",
    "full1 = pd.get_dummies(full1)\n",
    "full2 = pd.get_dummies(full2)\n",
    "full3 = pd.get_dummies(full3)\n",
    "full4 = pd.get_dummies(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 638)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 값\n",
    "# label 분리 SalePrice 부분, 그리고 log scale까지\n",
    "y = train['SalePrice']\n",
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 값들 (columns, features, inputs)\n",
    "n_train = train.shape[0]\n",
    "x1 = full1[:n_train]\n",
    "x2 = full2[:n_train]\n",
    "x3 = full3[:n_train]\n",
    "x4 = full4[:n_train]\n",
    "\n",
    "test_x1 = full1[n_train:]\n",
    "test_x2 = full2[n_train:]\n",
    "test_x3 = full3[n_train:]\n",
    "test_x4 = full4[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Model & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(alpha=0.01,max_iter=10000),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          SVR(),\n",
    "          LinearSVR(),\n",
    "          ElasticNet(alpha=0.001,max_iter=10000),\n",
    "          SGDRegressor(max_iter=1000,tol=1e-3),\n",
    "          BayesianRidge(),\n",
    "          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),\n",
    "          ]\n",
    "\n",
    "# if you have xgboost package, put XGBRegressor() in models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 5695.002996, 10104.9169\n",
      "Ridge: 0.154480, 0.0211\n",
      "Lasso: 0.190063, 0.0370\n",
      "RF: 0.159517, 0.0109\n",
      "GBR: 0.136248, 0.0113\n",
      "SVR: 0.397849, 0.0162\n",
      "LinSVR: 5.705883, 2.3262\n",
      "Ela: 0.137034, 0.0252\n",
      "SGD: 94861304249887952.000000, 37373237047621120.0000\n",
      "Bay: 0.142505, 0.0219\n",
      "Ker: 2.243725, 1.3767\n",
      "Extra: 0.162765, 0.0157\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x1 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 2395746080.863004, 2650053927.6431\n",
      "Ridge: 0.153850, 0.0187\n",
      "Lasso: 0.209864, 0.0166\n",
      "RF: 0.160690, 0.0099\n",
      "GBR: 0.135205, 0.0118\n",
      "SVR: 0.163891, 0.0122\n",
      "LinSVR: 0.174963, 0.0221\n",
      "Ela: 0.134248, 0.0175\n",
      "SGD: 0.240759, 0.0157\n",
      "Bay: 0.145871, 0.0157\n",
      "Ker: 0.160164, 0.0122\n",
      "Extra: 0.164468, 0.0146\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x2 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1572655774.586774, 1654773878.7078\n",
      "Ridge: 0.155112, 0.0222\n",
      "Lasso: 0.180672, 0.0239\n",
      "RF: 0.157593, 0.0112\n",
      "GBR: 0.136095, 0.0120\n",
      "SVR: 0.134181, 0.0122\n",
      "LinSVR: 0.177948, 0.0266\n",
      "Ela: 0.137374, 0.0250\n",
      "SGD: 0.266193, 0.0164\n",
      "Bay: 0.142825, 0.0221\n",
      "Ker: 0.138970, 0.0194\n",
      "Extra: 0.162734, 0.0193\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x3 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 6118849.805382, 10756533.1355\n",
      "Ridge: 0.155072, 0.0222\n",
      "Lasso: 0.183248, 0.0249\n",
      "RF: 0.157090, 0.0112\n",
      "GBR: 0.135944, 0.0129\n",
      "SVR: 0.223618, 0.0179\n",
      "LinSVR: 0.612395, 0.4610\n",
      "Ela: 0.137483, 0.0249\n",
      "SGD: 440932584788897.562500, 522404381266385.8125\n",
      "Bay: 0.142807, 0.0220\n",
      "Ker: 0.382613, 0.3316\n",
      "Extra: 0.164096, 0.0166\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x4 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search\n",
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13505469399196174\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.136359        0.005717\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.135366        0.005329\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.135055        0.004776\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.136180        0.004533\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13923735739691173\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.140456        0.007740\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.139771        0.007699\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.139237        0.007598\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.140025        0.007606\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13940379280237872\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.140549        0.007671\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.139833        0.007621\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.139404        0.007523\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.140172        0.007513\n"
     ]
    }
   ],
   "source": [
    "grid(Lasso()).grid_get(x2,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x3,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x4,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 35} 0.15065237072784315\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.150652        0.003750\n",
      "1  {'alpha': 40}         0.152161        0.003777\n",
      "2  {'alpha': 45}         0.153621        0.003808\n",
      "3  {'alpha': 50}         0.155029        0.003842\n",
      "4  {'alpha': 55}         0.156384        0.003876\n",
      "5  {'alpha': 60}         0.157689        0.003912\n",
      "6  {'alpha': 65}         0.158946        0.003948\n",
      "7  {'alpha': 70}         0.160156        0.003984\n",
      "8  {'alpha': 80}         0.162451        0.004055\n",
      "9  {'alpha': 90}         0.164593        0.004126\n",
      "{'alpha': 35} 0.14504820825045484\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.145048        0.007109\n",
      "1  {'alpha': 40}         0.145501        0.007168\n",
      "2  {'alpha': 45}         0.145965        0.007219\n",
      "3  {'alpha': 50}         0.146431        0.007264\n",
      "4  {'alpha': 55}         0.146891        0.007303\n",
      "5  {'alpha': 60}         0.147343        0.007338\n",
      "6  {'alpha': 65}         0.147784        0.007368\n",
      "7  {'alpha': 70}         0.148212        0.007394\n",
      "8  {'alpha': 80}         0.149032        0.007437\n",
      "9  {'alpha': 90}         0.149801        0.007470\n",
      "{'alpha': 35} 0.14467068242171985\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.144671        0.006987\n",
      "1  {'alpha': 40}         0.145111        0.007029\n",
      "2  {'alpha': 45}         0.145568        0.007066\n",
      "3  {'alpha': 50}         0.146030        0.007096\n",
      "4  {'alpha': 55}         0.146490        0.007122\n",
      "5  {'alpha': 60}         0.146944        0.007143\n",
      "6  {'alpha': 65}         0.147389        0.007161\n",
      "7  {'alpha': 70}         0.147825        0.007175\n",
      "8  {'alpha': 80}         0.148666        0.007196\n",
      "9  {'alpha': 90}         0.149463        0.007209\n"
     ]
    }
   ],
   "source": [
    "grid(Ridge()).grid_get(x2,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x3,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x4,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.13765284550807125\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.147435   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.146071   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.138672   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.137996   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.137653   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.142358   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.138285   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138384   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.146460   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.005753  \n",
      "1        0.005710  \n",
      "2        0.005333  \n",
      "3        0.004036  \n",
      "4        0.003965  \n",
      "5        0.003830  \n",
      "6        0.003865  \n",
      "7        0.003804  \n",
      "8        0.003910  \n",
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.14082967373859087\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149516   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148224   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.141413   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.140951   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.140830   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.144171   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.141112   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.141214   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.146882   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.007150  \n",
      "1        0.007129  \n",
      "2        0.007071  \n",
      "3        0.006927  \n",
      "4        0.007035  \n",
      "5        0.007637  \n",
      "6        0.007061  \n",
      "7        0.007147  \n",
      "8        0.007904  \n",
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.14081845940820897\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149520   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148240   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.141526   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.140939   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.140818   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.144146   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.141082   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.141178   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.146823   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.007138  \n",
      "1        0.007114  \n",
      "2        0.007042  \n",
      "3        0.006867  \n",
      "4        0.006961  \n",
      "5        0.007506  \n",
      "6        0.006986  \n",
      "7        0.007050  \n",
      "8        0.007765  \n"
     ]
    }
   ],
   "source": [
    "grid(ElasticNet()).grid_get(x2,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x3,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x4,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.15051501225923827\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.156816   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.150515   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.164699   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.156094   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.171700   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.161120   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.003413  \n",
      "1        0.003440  \n",
      "2        0.003498  \n",
      "3        0.003490  \n",
      "4        0.003591  \n",
      "5        0.003557  \n",
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.12801432117629127\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.132891   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.128014   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.138950   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.131888   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.144441   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.135569   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.002964  \n",
      "1        0.003046  \n",
      "2        0.003105  \n",
      "3        0.003042  \n",
      "4        0.003488  \n",
      "5        0.003182  \n",
      "{'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'kernel': 'polynomial'} 127.77487887327928\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...       128.167403   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...       252.827894   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...       127.774879   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...       251.501714   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...       127.938917   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...       250.766342   \n",
      "\n",
      "   std_test_score  \n",
      "0    32575.023161  \n",
      "1   127036.529840  \n",
      "2    32384.412253  \n",
      "3   125715.649426  \n",
      "4    32475.485409  \n",
      "5   124989.101640  \n"
     ]
    }
   ],
   "source": [
    "param_grid={'alpha':[0.2,0.3,0.4], 'kernel':[\"polynomial\"], 'degree':[3],'coef0':[0.8,1]}\n",
    "grid(KernelRidge()).grid_get(x2,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x3,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x4,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1313671368441154\n"
     ]
    }
   ],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "ridge = Ridge(alpha=35)\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()\n",
    "\n",
    "# assign weights based on their gridsearch score\n",
    "w1 = 0.2\n",
    "w2 = 0.1\n",
    "w3 = 0.0\n",
    "w4 = 0.5\n",
    "w5 = 0.2\n",
    "w6 = 0.0\n",
    "\n",
    "weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n",
    "\n",
    "\n",
    "score = rmse_cv(weight_avg,x3,y_log) #커널만 x3쓰기 pred에서 지금이 제일 낮은 item 찾음\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Result - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러모델 평균\n",
    "r1 = lasso.fit(x3, y_log)\n",
    "r2 = ridge.fit(x3,y_log)\n",
    "r3 = svr.fit(x3,y_log)\n",
    "r4 = ker.fit(x3,y_log)\n",
    "r5 = ela.fit(x3,y_log)\n",
    "r6 = bay.fit(x3,y_log)\n",
    "\n",
    "pred_r1 =np.exp(r1.predict(test_x3))\n",
    "pred_r2 =np.exp(r2.predict(test_x3))\n",
    "pred_r3 =np.exp(r3.predict(test_x3))\n",
    "pred_r4 =np.exp(r4.predict(test_x3))\n",
    "pred_r5 =np.exp(r5.predict(test_x3))\n",
    "pred_r6 =np.exp(r6.predict(test_x3))\n",
    "\n",
    "pred_final = w1 * pred_r1 + w2 * pred_r2 + w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 + w6 * pred_r6\n",
    "\n",
    "\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_final})\n",
    "result.to_csv(\"submission5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical 변수 mapping 해서 numeric으로 넣어주니까 스코어는 더 낮아짐.\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x2, x3 교차해서 결과내니 성능 더 낮아짐\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가로 해야할 것들, mapping 한 결과들 한 번 다 넣어보기. 그리고 lasso, 다른 결과들이 어떻게 내는지 확인해볼 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
