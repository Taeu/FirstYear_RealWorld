{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle House Price Prob.\n",
    "\n",
    "\n",
    "\n",
    "2018.10.20.Sat. By Taeu\n",
    "\n",
    "for Google Machine learning study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "\n",
    "# Content\n",
    "## 1. Data Skimming\n",
    "\n",
    "    1-1. Data collect\n",
    "    1-2. Data load\n",
    "    1-3. Data Skimming ( to excel _ )\n",
    "\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "    2-1. Fill NAs\n",
    "    2-2. Drop\n",
    "    2-3. Editing ( Adding, Editing, Binning etc..)\n",
    "    \n",
    "    \n",
    "## 3. Model & Evaluation\n",
    "\n",
    "    3-1 pipeline\n",
    "    3-2 Model Selection & Eval\n",
    "    3-3 Result - Submission\n",
    "    \n",
    "    \n",
    "*******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# install xgboost\\nhttp://cleancode-ws.tistory.com/79\\n# understanding xgboost\\nhttps://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#from xgboost import XGBRegressor\n",
    "# if you want to use XGBoost\n",
    "'''\n",
    "# install xgboost\n",
    "http://cleancode-ws.tistory.com/79\n",
    "# understanding xgboost\n",
    "https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Skimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "full = pd.concat([train,test],ignore_index=True)\n",
    "cols = train.columns\n",
    "nulls = full.isnull().sum()\n",
    "nulls = nulls[nulls>0]\n",
    "nulls_index = nulls.index\n",
    "datacols = []\n",
    "datanull = []\n",
    "datatype = []\n",
    "datavalue = []\n",
    "\n",
    "for col in cols:\n",
    "    datacols += [col]\n",
    "    datatype += [train[col].dtype]\n",
    "    datavalue+= [train[col][0]]\n",
    "    if col in nulls_index :\n",
    "        datanull += [nulls[col]]\n",
    "    else :\n",
    "        datanull += [0]\n",
    "        \n",
    "idd = list(range(cols.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])\n",
    "\n",
    "full['LotAreaCut']= pd.qcut(full.LotArea,10)\n",
    "\n",
    "full['LotFrontage'] = full.groupby(['LotAreaCut','Neighborhood'])['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "\n",
    "# 나머지 변수들은 다 0 이나 None 값으로\n",
    "# nulls_index = nulls.index\n",
    "\n",
    "for col in nulls_index:\n",
    "    na_value = 0\n",
    "    if full[col].dtype == object :\n",
    "        na_value = \"None\"\n",
    "    full[col].fillna(na_value, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. drop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이부분도 하나더 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = ['SalePrice','Id','Utilities']\n",
    "for var in drop_index:\n",
    "    full.drop([var],axis=1,inplace = True)\n",
    "#all_data = all_data.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) type 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_col = full.columns\n",
    "for var in full_col:\n",
    "    if full[var].dtype == object :\n",
    "        full[var] = full[var].astype(str)\n",
    "        \n",
    "time = ['MoSold','YrSold'] #여기서 Year bulit같은 경우는 categorical로 안ㄴ넣어주는게 ,'GarageYrBlt','YearBuilt','YearRemodAdd'는 뺌\n",
    "categorical = ['MSSubClass','OverallQual','OverallCond'] # OVERALL QUAL도 한 번\n",
    "strtype = time + categorical\n",
    "for var in strtype:\n",
    "    full[var] = full[var].astype(str)\n",
    "    \n",
    "full.drop('LotAreaCut',axis=1,inplace=True)\n",
    "full_col = full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2919, 78)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(full[c].values)) \n",
    "    full[c] = lbl.transform(list(full[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(full.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric 변수들 모음\n",
    "numeric_col = []\n",
    "for var in full_col:\n",
    "    if type(full[var][0]) != str:\n",
    "        numeric_col += [var]\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# ~.fit(data), ~.fit_transform()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "standard = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "\n",
    "# 각 scale을 따로 적용하기 위해서 full의 copy version을 만든다.\n",
    "full2 = full.copy()\n",
    "full3 = full.copy()\n",
    "full4 = full.copy()\n",
    "\n",
    "#full1 은 no scale\n",
    "full2[numeric_col] = minmax.fit_transform(full2[numeric_col])\n",
    "full3[numeric_col] = standard.fit_transform(full3[numeric_col])\n",
    "full4[numeric_col] = robust.fit_transform(full4[numeric_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) categorical 변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수 설정\n",
    "def map_values(full):\n",
    "    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n",
    "                                        '30':2, '45':2, \n",
    "                                        '190':3, '50':3, '90':3, \n",
    "                                        '85':4, '40':4, '160':4, \n",
    "                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                        '120': 6, '60':6})\n",
    "    \n",
    "    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n",
    "                                               'IDOTRR':2, 'BrDale':2,\n",
    "                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n",
    "                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n",
    "                                               'NPkVill':5, 'Mitchel':5,\n",
    "                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n",
    "                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n",
    "                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n",
    "                                               'StoneBr':9,\n",
    "                                               'NoRidge':10, 'NridgHt':10})\n",
    "    \n",
    "    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n",
    "    \n",
    "    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n",
    "                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n",
    "                                           '1Story':3, 'SLvl':3,\n",
    "                                           '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n",
    "                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n",
    "                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n",
    "                                             'BrkFace':4, 'Plywood':4,\n",
    "                                             'VinylSd':5,\n",
    "                                             'CemntBd':6,\n",
    "                                             'Stone':7, 'ImStucc':7})\n",
    "    \n",
    "    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n",
    "    \n",
    "    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n",
    "                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n",
    "                                           'Wood':3, 'PConc':4})\n",
    "    \n",
    "    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n",
    "    \n",
    "    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n",
    "    \n",
    "    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n",
    "    \n",
    "    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                           'Detchd':2,\n",
    "                                           '2Types':3, 'Basment':3,\n",
    "                                           'Attchd':4, 'BuiltIn':5})\n",
    "    \n",
    "    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n",
    "    \n",
    "    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n",
    "                                       'CWD':2, 'Con':3, 'New':3})\n",
    "    \n",
    "    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n",
    "                \n",
    "                        \n",
    "                        \n",
    "    \n",
    "    return full\n",
    "\n",
    "full2 = map_values(full2)\n",
    "full3 = map_values(full3)\n",
    "full4 = map_values(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = full2.columns\n",
    "for col in cols:\n",
    "    na_value = 0.0\n",
    "    full2[col].fillna(na_value, inplace = True)\n",
    "    full3[col].fillna(na_value, inplace = True)\n",
    "    full4[col].fillna(na_value, inplace = True)\n",
    "# mapping 한것들 NA 값들도 넣어주기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = full4.isnull().sum()\n",
    "aa[aa>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string -> one_hot_encoding\n",
    "full2 = pd.get_dummies(full2)\n",
    "full3 = pd.get_dummies(full3)\n",
    "full4 = pd.get_dummies(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 256)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full3.shape # 3개 뺐더니 확 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_None</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.773861</td>\n",
       "      <td>1.207379</td>\n",
       "      <td>-0.103331</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.169927</td>\n",
       "      <td>0.333532</td>\n",
       "      <td>0.584281</td>\n",
       "      <td>0.581145</td>\n",
       "      <td>-0.293025</td>\n",
       "      <td>-0.529329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261075</td>\n",
       "      <td>-0.785025</td>\n",
       "      <td>-0.103331</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.169927</td>\n",
       "      <td>0.333532</td>\n",
       "      <td>-1.153382</td>\n",
       "      <td>1.178255</td>\n",
       "      <td>-0.293025</td>\n",
       "      <td>-1.424268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.610718</td>\n",
       "      <td>1.235375</td>\n",
       "      <td>-0.103331</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.169927</td>\n",
       "      <td>0.333532</td>\n",
       "      <td>-0.284550</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>-0.293025</td>\n",
       "      <td>-0.529329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch    Alley  BedroomAbvGr  BsmtCond  \\\n",
       "0 -0.773861  1.207379  -0.103331  0.05533      0.169927  0.333532   \n",
       "1  0.261075 -0.785025  -0.103331  0.05533      0.169927  0.333532   \n",
       "2 -0.610718  1.235375  -0.103331  0.05533      0.169927  0.333532   \n",
       "\n",
       "   BsmtExposure  BsmtFinSF1  BsmtFinSF2  BsmtFinType1     ...       \\\n",
       "0      0.584281    0.581145   -0.293025     -0.529329     ...        \n",
       "1     -1.153382    1.178255   -0.293025     -1.424268     ...        \n",
       "2     -0.284550    0.098189   -0.293025     -0.529329     ...        \n",
       "\n",
       "   SaleType_COD  SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  \\\n",
       "0             0             0             0               0               0   \n",
       "1             0             0             0               0               0   \n",
       "2             0             0             0               0               0   \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_None  SaleType_Oth  SaleType_WD  \n",
       "0               0             0              0             0            1  \n",
       "1               0             0              0             0            1  \n",
       "2               0             0              0             0            1  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 값\n",
    "# label 분리 SalePrice 부분, 그리고 log scale까지\n",
    "y = train['SalePrice']\n",
    "y_log = np.log(y)\n",
    "# x 값들 (columns, features, inputs)\n",
    "n_train = train.shape[0]\n",
    "x2 = full2[:n_train]\n",
    "x3 = full3[:n_train]\n",
    "x4 = full4[:n_train]\n",
    "\n",
    "test_x2 = full2[n_train:]\n",
    "test_x3 = full3[n_train:]\n",
    "test_x4 = full4[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Model & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(alpha=0.01,max_iter=10000),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          SVR(),\n",
    "          LinearSVR(),\n",
    "          ElasticNet(alpha=0.001,max_iter=10000),\n",
    "          SGDRegressor(max_iter=1000,tol=1e-3),\n",
    "          BayesianRidge(),\n",
    "          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),\n",
    "          ]\n",
    "\n",
    "# if you have xgboost package, put XGBRegressor() in models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 29837821037.726940, 21960374273.8700\n",
      "Ridge: 0.141505, 0.0220\n",
      "Lasso: 0.211857, 0.0101\n",
      "RF: 0.148027, 0.0060\n",
      "GBR: 0.126967, 0.0090\n",
      "SVR: 0.150639, 0.0100\n",
      "LinSVR: 0.161677, 0.0288\n",
      "Ela: 0.136441, 0.0177\n",
      "SGD: 0.255376, 0.0273\n",
      "Bay: 0.141818, 0.0213\n",
      "Ker: 0.146064, 0.0092\n",
      "Extra: 0.145369, 0.0104\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x2 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1258159346.755315, 729709599.2674\n",
      "Ridge: 0.145973, 0.0280\n",
      "Lasso: 0.152709, 0.0205\n",
      "RF: 0.154961, 0.0079\n",
      "GBR: 0.126988, 0.0083\n",
      "SVR: 0.132268, 0.0128\n",
      "LinSVR: 0.167640, 0.0401\n",
      "Ela: 0.138750, 0.0252\n",
      "SGD: 0.284676, 0.0263\n",
      "Bay: 0.142381, 0.0237\n",
      "Ker: 0.123320, 0.0114\n",
      "Extra: 0.142296, 0.0116\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x3 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.156675, 0.0295\n",
      "Ridge: 0.145254, 0.0269\n",
      "Lasso: 0.158377, 0.0194\n",
      "RF: 0.150296, 0.0096\n",
      "GBR: 0.126642, 0.0101\n",
      "SVR: 0.220826, 0.0182\n",
      "LinSVR: 0.376354, 0.3782\n",
      "Ela: 0.138651, 0.0249\n",
      "SGD: 668550122787479.250000, 871067576268246.8750\n",
      "Bay: 0.141366, 0.0229\n",
      "Ker: 0.318727, 0.2597\n",
      "Extra: 0.145071, 0.0114\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x4 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search\n",
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0005, 'max_iter': 10000} 0.13787485071371244\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.138528        0.006409\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.137875        0.005899\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.137978        0.005148\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.139666        0.004513\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.1406892941790436\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.141677        0.008225\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.141025        0.008062\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.140689        0.007676\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.141455        0.007389\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.14058649171224794\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.141714        0.008136\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.141003        0.007950\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.140586        0.007567\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.141330        0.007245\n"
     ]
    }
   ],
   "source": [
    "grid(Lasso()).grid_get(x2,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x3,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x4,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 35} 0.1520051968716624\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.152005        0.002791\n",
      "1  {'alpha': 40}         0.153966        0.002790\n",
      "2  {'alpha': 45}         0.155810        0.002799\n",
      "3  {'alpha': 50}         0.157548        0.002816\n",
      "4  {'alpha': 55}         0.159188        0.002837\n",
      "5  {'alpha': 60}         0.160740        0.002862\n",
      "6  {'alpha': 65}         0.162210        0.002890\n",
      "7  {'alpha': 70}         0.163606        0.002918\n",
      "8  {'alpha': 80}         0.166201        0.002979\n",
      "9  {'alpha': 90}         0.168567        0.003041\n",
      "{'alpha': 35} 0.14391812474690602\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.143918        0.007177\n",
      "1  {'alpha': 40}         0.143948        0.007128\n",
      "2  {'alpha': 45}         0.143979        0.007084\n",
      "3  {'alpha': 50}         0.144009        0.007044\n",
      "4  {'alpha': 55}         0.144038        0.007007\n",
      "5  {'alpha': 60}         0.144065        0.006972\n",
      "6  {'alpha': 65}         0.144090        0.006939\n",
      "7  {'alpha': 70}         0.144112        0.006908\n",
      "8  {'alpha': 80}         0.144152        0.006850\n",
      "9  {'alpha': 90}         0.144186        0.006795\n",
      "{'alpha': 35} 0.14282415075128296\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.142824        0.006647\n",
      "1  {'alpha': 40}         0.142904        0.006595\n",
      "2  {'alpha': 45}         0.142985        0.006545\n",
      "3  {'alpha': 50}         0.143065        0.006497\n",
      "4  {'alpha': 55}         0.143145        0.006451\n",
      "5  {'alpha': 60}         0.143223        0.006406\n",
      "6  {'alpha': 65}         0.143300        0.006363\n",
      "7  {'alpha': 70}         0.143375        0.006321\n",
      "8  {'alpha': 80}         0.143521        0.006240\n",
      "9  {'alpha': 90}         0.143662        0.006162\n"
     ]
    }
   ],
   "source": [
    "grid(Ridge()).grid_get(x2,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x3,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x4,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter': 10000} 0.1385196227072876\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.141073   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.140651   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.138520   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.138678   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.138938   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.143784   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.139547   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.140029   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.147196   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.006234  \n",
      "1        0.006179  \n",
      "2        0.005802  \n",
      "3        0.003757  \n",
      "4        0.003667  \n",
      "5        0.003058  \n",
      "6        0.003487  \n",
      "7        0.003403  \n",
      "8        0.002767  \n",
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.14188491093580052\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.146059   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.145482   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.142115   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.141896   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.141885   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.143399   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.142034   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.142165   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.144312   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.008387  \n",
      "1        0.008323  \n",
      "2        0.007946  \n",
      "3        0.007134  \n",
      "4        0.007116  \n",
      "5        0.007039  \n",
      "6        0.007087  \n",
      "7        0.007077  \n",
      "8        0.007068  \n",
      "{'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter': 10000} 0.1414073489810102\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.145129   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.144537   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.141562   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.141407   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.141441   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.143302   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.141550   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.141696   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.144323   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.007911  \n",
      "1        0.007834  \n",
      "2        0.007639  \n",
      "3        0.006895  \n",
      "4        0.006879  \n",
      "5        0.006887  \n",
      "6        0.006830  \n",
      "7        0.006802  \n",
      "8        0.006919  \n"
     ]
    }
   ],
   "source": [
    "grid(ElasticNet()).grid_get(x2,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x3,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x4,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2, 'coef0': 2.5, 'degree': 2, 'kernel': 'polynomial'} 0.12050425838478991\n",
      "                                               params  mean_test_score  \\\n",
      "0   {'alpha': 0.2, 'coef0': 0.8, 'degree': 2, 'ker...         0.133399   \n",
      "1   {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.150300   \n",
      "2   {'alpha': 0.2, 'coef0': 0.8, 'degree': 4, 'ker...         0.179555   \n",
      "3   {'alpha': 0.2, 'coef0': 1, 'degree': 2, 'kerne...         0.127397   \n",
      "4   {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.137781   \n",
      "5   {'alpha': 0.2, 'coef0': 1, 'degree': 4, 'kerne...         0.157245   \n",
      "6   {'alpha': 0.2, 'coef0': 2.5, 'degree': 2, 'ker...         0.120504   \n",
      "7   {'alpha': 0.2, 'coef0': 2.5, 'degree': 3, 'ker...         0.126724   \n",
      "8   {'alpha': 0.2, 'coef0': 2.5, 'degree': 4, 'ker...         0.137958   \n",
      "9   {'alpha': 0.3, 'coef0': 0.8, 'degree': 2, 'ker...         0.139549   \n",
      "10  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.156129   \n",
      "11  {'alpha': 0.3, 'coef0': 0.8, 'degree': 4, 'ker...         0.185237   \n",
      "12  {'alpha': 0.3, 'coef0': 1, 'degree': 2, 'kerne...         0.131298   \n",
      "13  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.140377   \n",
      "14  {'alpha': 0.3, 'coef0': 1, 'degree': 4, 'kerne...         0.159294   \n",
      "15  {'alpha': 0.3, 'coef0': 2.5, 'degree': 2, 'ker...         0.121003   \n",
      "16  {'alpha': 0.3, 'coef0': 2.5, 'degree': 3, 'ker...         0.124958   \n",
      "17  {'alpha': 0.3, 'coef0': 2.5, 'degree': 4, 'ker...         0.135393   \n",
      "18  {'alpha': 0.4, 'coef0': 0.8, 'degree': 2, 'ker...         0.145647   \n",
      "19  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.162043   \n",
      "20  {'alpha': 0.4, 'coef0': 0.8, 'degree': 4, 'ker...         0.190905   \n",
      "21  {'alpha': 0.4, 'coef0': 1, 'degree': 2, 'kerne...         0.135381   \n",
      "22  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.143398   \n",
      "23  {'alpha': 0.4, 'coef0': 1, 'degree': 4, 'kerne...         0.161739   \n",
      "24  {'alpha': 0.4, 'coef0': 2.5, 'degree': 2, 'ker...         0.121867   \n",
      "25  {'alpha': 0.4, 'coef0': 2.5, 'degree': 3, 'ker...         0.123906   \n",
      "26  {'alpha': 0.4, 'coef0': 2.5, 'degree': 4, 'ker...         0.133667   \n",
      "27  {'alpha': 0.5, 'coef0': 0.8, 'degree': 2, 'ker...         0.151493   \n",
      "28  {'alpha': 0.5, 'coef0': 0.8, 'degree': 3, 'ker...         0.167854   \n",
      "29  {'alpha': 0.5, 'coef0': 0.8, 'degree': 4, 'ker...         0.196438   \n",
      "30  {'alpha': 0.5, 'coef0': 1, 'degree': 2, 'kerne...         0.139411   \n",
      "31  {'alpha': 0.5, 'coef0': 1, 'degree': 3, 'kerne...         0.146582   \n",
      "32  {'alpha': 0.5, 'coef0': 1, 'degree': 4, 'kerne...         0.164338   \n",
      "33  {'alpha': 0.5, 'coef0': 2.5, 'degree': 2, 'ker...         0.122846   \n",
      "34  {'alpha': 0.5, 'coef0': 2.5, 'degree': 3, 'ker...         0.123225   \n",
      "35  {'alpha': 0.5, 'coef0': 2.5, 'degree': 4, 'ker...         0.132406   \n",
      "36  {'alpha': 0.6, 'coef0': 0.8, 'degree': 2, 'ker...         0.157042   \n",
      "37  {'alpha': 0.6, 'coef0': 0.8, 'degree': 3, 'ker...         0.173498   \n",
      "38  {'alpha': 0.6, 'coef0': 0.8, 'degree': 4, 'ker...         0.201804   \n",
      "39  {'alpha': 0.6, 'coef0': 1, 'degree': 2, 'kerne...         0.143311   \n",
      "40  {'alpha': 0.6, 'coef0': 1, 'degree': 3, 'kerne...         0.149822   \n",
      "41  {'alpha': 0.6, 'coef0': 1, 'degree': 4, 'kerne...         0.166998   \n",
      "42  {'alpha': 0.6, 'coef0': 2.5, 'degree': 2, 'ker...         0.123850   \n",
      "43  {'alpha': 0.6, 'coef0': 2.5, 'degree': 3, 'ker...         0.122769   \n",
      "44  {'alpha': 0.6, 'coef0': 2.5, 'degree': 4, 'ker...         0.131434   \n",
      "\n",
      "    std_test_score  \n",
      "0         0.002844  \n",
      "1         0.003343  \n",
      "2         0.004605  \n",
      "3         0.002774  \n",
      "4         0.003089  \n",
      "5         0.003679  \n",
      "6         0.002842  \n",
      "7         0.002791  \n",
      "8         0.002524  \n",
      "9         0.002990  \n",
      "10        0.003490  \n",
      "11        0.004829  \n",
      "12        0.002819  \n",
      "13        0.003143  \n",
      "14        0.003776  \n",
      "15        0.002784  \n",
      "16        0.002902  \n",
      "17        0.002533  \n",
      "18        0.003212  \n",
      "19        0.003660  \n",
      "20        0.005062  \n",
      "21        0.002928  \n",
      "22        0.003192  \n",
      "23        0.003867  \n",
      "24        0.002772  \n",
      "25        0.002958  \n",
      "26        0.002577  \n",
      "27        0.003474  \n",
      "28        0.003854  \n",
      "29        0.005304  \n",
      "30        0.003078  \n",
      "31        0.003248  \n",
      "32        0.003953  \n",
      "33        0.002795  \n",
      "34        0.002985  \n",
      "35        0.002629  \n",
      "36        0.003753  \n",
      "37        0.004066  \n",
      "38        0.005551  \n",
      "39        0.003250  \n",
      "40        0.003314  \n",
      "41        0.004039  \n",
      "42        0.002843  \n",
      "43        0.002998  \n",
      "44        0.002679  \n"
     ]
    }
   ],
   "source": [
    "param_grid={'alpha':[0.2,0.3,0.4,0.5,0.6], 'kernel':[\"polynomial\"], 'degree':[2,3,4],'coef0':[0.8,1,2.5]}\n",
    "grid(KernelRidge()).grid_get(x3,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1164519174726026\n"
     ]
    }
   ],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "gbr = GradientBoostingRegressor()\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=2 , coef0=2.5)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()\n",
    "\n",
    "# assign weights based on their gridsearch score\n",
    "w1 = 0.0\n",
    "w2 = 0.3\n",
    "w3 = 0.1\n",
    "w4 = 0.6\n",
    "w5 = 0.0\n",
    "w6 = 0.0\n",
    "\n",
    "weight_avg = AverageWeight(mod = [lasso,gbr,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n",
    "\n",
    "\n",
    "score = rmse_cv(weight_avg,x3,y_log) #커널만 x3쓰기 pred에서 지금이 제일 낮은 item 찾음\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Result - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러모델 평균\n",
    "r1 = lasso.fit(x3,y_log)\n",
    "r2 = gbr.fit(x3,y_log)\n",
    "r3 = svr.fit(x3,y_log)\n",
    "r4 = ker.fit(x3,y_log)\n",
    "r5 = ela.fit(x3,y_log)\n",
    "r6 = bay.fit(x3,y_log)\n",
    "\n",
    "pred_r1 =np.exp(r1.predict(test_x3))\n",
    "pred_r2 =np.exp(r2.predict(test_x3))\n",
    "pred_r3 =np.exp(r3.predict(test_x3))\n",
    "pred_r4 =np.exp(r4.predict(test_x3))\n",
    "pred_r5 =np.exp(r5.predict(test_x3))\n",
    "pred_r6 =np.exp(r6.predict(test_x3))\n",
    "\n",
    "pred_final = w1 * pred_r1 + w2 * pred_r2 + w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 + w6 * pred_r6\n",
    "#pred_final =  w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 \n",
    "\n",
    "\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_final})\n",
    "result.to_csv(\"submission9.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical 변수 mapping 해서 numeric으로 넣어주니까 스코어는 더 낮아짐.\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x2, x3 교차해서 결과내니 성능 더 낮아짐\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가로 해야할 것들, mapping 한 결과들 한 번 다 넣어보기. 그리고 lasso, 다른 결과들이 어떻게 내는지 확인해볼 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\")\n",
    "# 0.01 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47237501-43691b00-d41a-11e8-8c44-1ea5e674b9a4.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47237501-43691b00-d41a-11e8-8c44-1ea5e674b9a4.PNG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skew-processing 고려해야함\n",
    "# 참고 url : https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box Cox Transformation of (highly) skewed features\n",
    "\n",
    "We use the scipy function boxcox1p which computes the Box-Cox transformation of  1+x .\n",
    "\n",
    "Note that setting  λ=0  is equivalent to log1p used above for the target variable.\n",
    "\n",
    "See this page for more details on Box Cox Transformation as well as the scipy function's page\n",
    "\n",
    "http://onlinestatbook.com/2/transformations/box-cox.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoder - categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47244917-440dab80-d432-11e8-95cc-58f9b11202a8.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47244917-440dab80-d432-11e8-95cc-58f9b11202a8.PNG\")\n",
    "# size ( cols =500개 / 상위랭크 200개) \n",
    "# https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47245910-2c382680-d436-11e8-98a6-225f5b42456c.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 250개로 조정한 스코어\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47245910-2c382680-d436-11e8-98a6-225f5b42456c.PNG\")\n",
    "\n",
    "# TOP 25~30 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
