{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle House Price Prob.\n",
    "\n",
    "\n",
    "\n",
    "2018.10.20.Sat. By Taeu\n",
    "\n",
    "for Google Machine learning study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "\n",
    "# Content\n",
    "## 1. Data Skimming\n",
    "\n",
    "    1-1. Data collect\n",
    "    1-2. Data load\n",
    "    1-3. Data Skimming ( to excel _ )\n",
    "\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "    2-1. Fill NAs\n",
    "    2-2. Drop\n",
    "    2-3. Editing ( Adding, Editing, Binning etc..)\n",
    "    \n",
    "    \n",
    "## 3. Model & Evaluation\n",
    "\n",
    "    3-1 pipeline\n",
    "    3-2 Model Selection & Eval\n",
    "    3-3 Result - Submission\n",
    "    \n",
    "    \n",
    "*******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# install xgboost\\nhttp://cleancode-ws.tistory.com/79\\n# understanding xgboost\\nhttps://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#from xgboost import XGBRegressor\n",
    "# if you want to use XGBoost\n",
    "'''\n",
    "# install xgboost\n",
    "http://cleancode-ws.tistory.com/79\n",
    "# understanding xgboost\n",
    "https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Skimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "full = pd.concat([train,test],ignore_index=True)\n",
    "cols = train.columns\n",
    "nulls = full.isnull().sum()\n",
    "nulls = nulls[nulls>0]\n",
    "nulls_index = nulls.index\n",
    "datacols = []\n",
    "datanull = []\n",
    "datatype = []\n",
    "datavalue = []\n",
    "\n",
    "for col in cols:\n",
    "    datacols += [col]\n",
    "    datatype += [train[col].dtype]\n",
    "    datavalue+= [train[col][0]]\n",
    "    if col in nulls_index :\n",
    "        datanull += [nulls[col]]\n",
    "    else :\n",
    "        datanull += [0]\n",
    "        \n",
    "idd = list(range(cols.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])\n",
    "\n",
    "full['LotAreaCut']= pd.qcut(full.LotArea,10)\n",
    "\n",
    "full['LotFrontage'] = full.groupby(['LotAreaCut','Neighborhood'])['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "\n",
    "# 나머지 변수들은 다 0 이나 None 값으로\n",
    "# nulls_index = nulls.index\n",
    "\n",
    "for col in nulls_index:\n",
    "    na_value = 0\n",
    "    if full[col].dtype == object :\n",
    "        na_value = \"None\"\n",
    "    full[col].fillna(na_value, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = ['SalePrice','Id']\n",
    "for var in drop_index:\n",
    "    full.drop([var],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) type 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_col = full.columns\n",
    "for var in full_col:\n",
    "    if full[var].dtype == object :\n",
    "        full[var] = full[var].astype(str)\n",
    "        \n",
    "time = ['GarageYrBlt','YearBuilt','YearRemodAdd','MoSold','YrSold']\n",
    "categorical = ['MSSubClass','OverallQual','OverallCond',]\n",
    "strtype = time + categorical\n",
    "for var in strtype:\n",
    "    full[var] = full[var].astype(str)\n",
    "    \n",
    "full.drop('LotAreaCut',axis=1,inplace=True)\n",
    "full_col = full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric 변수들 모음\n",
    "numeric_col = []\n",
    "for var in full_col:\n",
    "    if type(full[var][0]) != str:\n",
    "        numeric_col += [var]\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# ~.fit(data), ~.fit_transform()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "standard = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "\n",
    "# 각 scale을 따로 적용하기 위해서 full의 copy version을 만든다.\n",
    "full2 = full.copy()\n",
    "full3 = full.copy()\n",
    "full4 = full.copy()\n",
    "\n",
    "#full1 은 no scale\n",
    "full2[numeric_col] = minmax.fit_transform(full2[numeric_col])\n",
    "full3[numeric_col] = standard.fit_transform(full3[numeric_col])\n",
    "full4[numeric_col] = robust.fit_transform(full4[numeric_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) categorical 변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수 설정\n",
    "def map_values(full):\n",
    "    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n",
    "                                        '30':2, '45':2, \n",
    "                                        '190':3, '50':3, '90':3, \n",
    "                                        '85':4, '40':4, '160':4, \n",
    "                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                        '120': 6, '60':6})\n",
    "    \n",
    "    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n",
    "                                               'IDOTRR':2, 'BrDale':2,\n",
    "                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n",
    "                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n",
    "                                               'NPkVill':5, 'Mitchel':5,\n",
    "                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n",
    "                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n",
    "                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n",
    "                                               'StoneBr':9,\n",
    "                                               'NoRidge':10, 'NridgHt':10})\n",
    "    \n",
    "    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n",
    "    \n",
    "    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n",
    "                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n",
    "                                           '1Story':3, 'SLvl':3,\n",
    "                                           '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n",
    "                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n",
    "                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n",
    "                                             'BrkFace':4, 'Plywood':4,\n",
    "                                             'VinylSd':5,\n",
    "                                             'CemntBd':6,\n",
    "                                             'Stone':7, 'ImStucc':7})\n",
    "    \n",
    "    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n",
    "    \n",
    "    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n",
    "                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n",
    "                                           'Wood':3, 'PConc':4})\n",
    "    \n",
    "    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n",
    "    \n",
    "    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n",
    "    \n",
    "    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n",
    "    \n",
    "    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                           'Detchd':2,\n",
    "                                           '2Types':3, 'Basment':3,\n",
    "                                           'Attchd':4, 'BuiltIn':5})\n",
    "    \n",
    "    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n",
    "    \n",
    "    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n",
    "                                       'CWD':2, 'Con':3, 'New':3})\n",
    "    \n",
    "    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n",
    "                \n",
    "                        \n",
    "                        \n",
    "    \n",
    "    return full\n",
    "\n",
    "full2 = map_values(full2)\n",
    "full3 = map_values(full3)\n",
    "full4 = map_values(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = full2.columns\n",
    "for col in cols:\n",
    "    na_value = 0\n",
    "    full2[col].fillna(na_value, inplace = True)\n",
    "    full3[col].fillna(na_value, inplace = True)\n",
    "    full4[col].fillna(na_value, inplace = True)\n",
    "# mapping 한것들 NA 값들도 넣어주기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = full4.isnull().sum()\n",
    "aa[aa>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cols:\n",
    "    if full4[var].dtype == int :\n",
    "        full2[var] = full2[var].astype(float)\n",
    "        full3[var] = full3[var].astype(float)\n",
    "        full4[var] = full4[var].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string -> one_hot_encoding\n",
    "full2 = pd.get_dummies(full2)\n",
    "full3 = pd.get_dummies(full3)\n",
    "full4 = pd.get_dummies(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 659)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 값\n",
    "# label 분리 SalePrice 부분, 그리고 log scale까지\n",
    "y = train['SalePrice']\n",
    "y_log = np.log(y)\n",
    "# x 값들 (columns, features, inputs)\n",
    "n_train = train.shape[0]\n",
    "x2 = full2[:n_train]\n",
    "x3 = full3[:n_train]\n",
    "x4 = full4[:n_train]\n",
    "\n",
    "test_x2 = full2[n_train:]\n",
    "test_x3 = full3[n_train:]\n",
    "test_x4 = full4[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Model & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(alpha=0.01,max_iter=10000),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          SVR(),\n",
    "          LinearSVR(),\n",
    "          ElasticNet(alpha=0.001,max_iter=10000),\n",
    "          SGDRegressor(max_iter=1000,tol=1e-3),\n",
    "          BayesianRidge(),\n",
    "          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),\n",
    "          ]\n",
    "\n",
    "# if you have xgboost package, put XGBRegressor() in models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1086474718.444026, 828495562.5575\n",
      "Ridge: 0.154392, 0.0181\n",
      "Lasso: 0.197213, 0.0110\n",
      "RF: 0.151949, 0.0058\n",
      "GBR: 0.130941, 0.0105\n",
      "SVR: 0.156649, 0.0095\n",
      "LinSVR: 0.170574, 0.0254\n",
      "Ela: 0.134769, 0.0146\n",
      "SGD: 0.235295, 0.0256\n",
      "Bay: 0.145310, 0.0137\n",
      "Ker: 0.154733, 0.0087\n",
      "Extra: 0.152235, 0.0128\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x2 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1104457511.899359, 1869047709.1687\n",
      "Ridge: 0.155605, 0.0216\n",
      "Lasso: 0.160540, 0.0175\n",
      "RF: 0.150792, 0.0111\n",
      "GBR: 0.130811, 0.0103\n",
      "SVR: 0.128753, 0.0104\n",
      "LinSVR: 0.178378, 0.0244\n",
      "Ela: 0.136310, 0.0224\n",
      "SGD: 0.250555, 0.0309\n",
      "Bay: 0.140253, 0.0197\n",
      "Ker: 0.132936, 0.0154\n",
      "Extra: 0.156889, 0.0140\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x3 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 19812305.258886, 27840045.0994\n",
      "Ridge: 0.155564, 0.0216\n",
      "Lasso: 0.162120, 0.0175\n",
      "RF: 0.148771, 0.0109\n",
      "GBR: 0.131043, 0.0104\n",
      "SVR: 0.212453, 0.0169\n",
      "LinSVR: 0.296169, 0.0875\n",
      "Ela: 0.136677, 0.0222\n",
      "SGD: 317817739427472.125000, 181567248161772.5625\n",
      "Bay: 0.140340, 0.0195\n",
      "Ker: 0.344521, 0.3401\n",
      "Extra: 0.150907, 0.0158\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x4 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search\n",
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13482401197506705\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.136027        0.005014\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.134923        0.004507\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.134824        0.003929\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.135922        0.003578\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13743098522108793\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.138768        0.006996\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.137967        0.006894\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.137431        0.006708\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.138097        0.006517\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13763850030947286\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.138993        0.006959\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.138303        0.006853\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.137639        0.006631\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.138369        0.006410\n"
     ]
    }
   ],
   "source": [
    "grid(Lasso()).grid_get(x2,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x3,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x4,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 35} 0.14891651284960963\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.148917        0.002732\n",
      "1  {'alpha': 40}         0.149991        0.002707\n",
      "2  {'alpha': 45}         0.151016        0.002691\n",
      "3  {'alpha': 50}         0.151991        0.002681\n",
      "4  {'alpha': 55}         0.152918        0.002676\n",
      "5  {'alpha': 60}         0.153799        0.002674\n",
      "6  {'alpha': 65}         0.154639        0.002676\n",
      "7  {'alpha': 70}         0.155439        0.002679\n",
      "8  {'alpha': 80}         0.156934        0.002691\n",
      "9  {'alpha': 90}         0.158306        0.002707\n",
      "{'alpha': 35} 0.1410153930180887\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.141015        0.005849\n",
      "1  {'alpha': 40}         0.141025        0.005852\n",
      "2  {'alpha': 45}         0.141077        0.005856\n",
      "3  {'alpha': 50}         0.141157        0.005858\n",
      "4  {'alpha': 55}         0.141256        0.005860\n",
      "5  {'alpha': 60}         0.141368        0.005861\n",
      "6  {'alpha': 65}         0.141488        0.005860\n",
      "7  {'alpha': 70}         0.141613        0.005859\n",
      "8  {'alpha': 80}         0.141873        0.005854\n",
      "9  {'alpha': 90}         0.142137        0.005845\n",
      "{'alpha': 35} 0.14078648984152692\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.140786        0.005685\n",
      "1  {'alpha': 40}         0.140801        0.005671\n",
      "2  {'alpha': 45}         0.140860        0.005658\n",
      "3  {'alpha': 50}         0.140949        0.005645\n",
      "4  {'alpha': 55}         0.141059        0.005632\n",
      "5  {'alpha': 60}         0.141184        0.005619\n",
      "6  {'alpha': 65}         0.141318        0.005605\n",
      "7  {'alpha': 70}         0.141459        0.005591\n",
      "8  {'alpha': 80}         0.141753        0.005563\n",
      "9  {'alpha': 90}         0.142053        0.005534\n"
     ]
    }
   ],
   "source": [
    "grid(Ridge()).grid_get(x2,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x3,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x4,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.13796599583461197\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.147658   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.146308   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.138468   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.138163   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.137966   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.141983   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.138502   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138601   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.145411   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.005417  \n",
      "1        0.005331  \n",
      "2        0.004820  \n",
      "3        0.003373  \n",
      "4        0.003232  \n",
      "5        0.002677  \n",
      "6        0.003093  \n",
      "7        0.002956  \n",
      "8        0.002587  \n",
      "{'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': 10000} 0.1388437892885677\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149531   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148151   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.140466   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.139342   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.139030   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.140389   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.139052   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138844   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.142367   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.006789  \n",
      "1        0.006717  \n",
      "2        0.006458  \n",
      "3        0.006073  \n",
      "4        0.006128  \n",
      "5        0.006445  \n",
      "6        0.006110  \n",
      "7        0.006157  \n",
      "8        0.006549  \n",
      "{'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': 10000} 0.13894298286651846\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149525   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148151   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.140549   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.139359   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.139073   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.140487   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.139066   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138943   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.142531   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.006779  \n",
      "1        0.006704  \n",
      "2        0.006437  \n",
      "3        0.006014  \n",
      "4        0.006045  \n",
      "5        0.006272  \n",
      "6        0.006021  \n",
      "7        0.006068  \n",
      "8        0.006374  \n"
     ]
    }
   ],
   "source": [
    "grid(ElasticNet()).grid_get(x2,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x3,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x4,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.1474327630602572\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.153305   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.147433   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.159754   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.151845   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.165367   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.155742   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.002839  \n",
      "1        0.002657  \n",
      "2        0.003064  \n",
      "3        0.002736  \n",
      "4        0.003298  \n",
      "5        0.002836  \n",
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.12805517789781531\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.134592   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.128055   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.140248   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.131234   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.145564   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.134409   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.002197  \n",
      "1        0.002277  \n",
      "2        0.002184  \n",
      "3        0.002243  \n",
      "4        0.002244  \n",
      "5        0.002254  \n",
      "{'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'kernel': 'polynomial'} 10.038633365635079\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...        10.038633   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...        52.887728   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...        20.722741   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...        44.015970   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...        30.850963   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...        34.728195   \n",
      "\n",
      "   std_test_score  \n",
      "0      128.775497  \n",
      "1     5591.076191  \n",
      "2      713.376553  \n",
      "3     3870.782609  \n",
      "4     1699.431537  \n",
      "5     2400.239215  \n"
     ]
    }
   ],
   "source": [
    "param_grid={'alpha':[0.2,0.3,0.4], 'kernel':[\"polynomial\"], 'degree':[3],'coef0':[0.8,1]}\n",
    "grid(KernelRidge()).grid_get(x2,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x3,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x4,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12698408960784605\n"
     ]
    }
   ],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "ridge = Ridge(alpha=35)\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()\n",
    "\n",
    "# assign weights based on their gridsearch score\n",
    "w1 = 0.1\n",
    "w2 = 0.0\n",
    "w3 = 0.2\n",
    "w4 = 0.5\n",
    "w5 = 0.2\n",
    "w6 = 0.0\n",
    "\n",
    "weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n",
    "\n",
    "\n",
    "score = rmse_cv(weight_avg,x3,y_log) #커널만 x3쓰기 pred에서 지금이 제일 낮은 item 찾음\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Result - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러모델 평균\n",
    "r1 = lasso.fit(x3,y_log)\n",
    "r2 = ridge.fit(x3,y_log)\n",
    "r3 = svr.fit(x3,y_log)\n",
    "r4 = ker.fit(x3,y_log)\n",
    "r5 = ela.fit(x3,y_log)\n",
    "r6 = bay.fit(x3,y_log)\n",
    "\n",
    "pred_r1 =np.exp(r1.predict(test_x3))\n",
    "pred_r2 =np.exp(r2.predict(test_x3))\n",
    "pred_r3 =np.exp(r3.predict(test_x3))\n",
    "pred_r4 =np.exp(r4.predict(test_x3))\n",
    "pred_r5 =np.exp(r5.predict(test_x3))\n",
    "pred_r6 =np.exp(r6.predict(test_x3))\n",
    "\n",
    "pred_final = w1 * pred_r1 + w2 * pred_r2 + w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 + w6 * pred_r6\n",
    "#pred_final =  w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 \n",
    "\n",
    "\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_final})\n",
    "result.to_csv(\"submission6.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical 변수 mapping 해서 numeric으로 넣어주니까 스코어는 더 낮아짐.\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x2, x3 교차해서 결과내니 성능 더 낮아짐\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가로 해야할 것들, mapping 한 결과들 한 번 다 넣어보기. 그리고 lasso, 다른 결과들이 어떻게 내는지 확인해볼 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\")\n",
    "# 0.01 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
