{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle House Price Prob.\n",
    "\n",
    "\n",
    "\n",
    "2018.10.20.Sat. By Taeu\n",
    "\n",
    "for Google Machine learning study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "\n",
    "# Content\n",
    "## 1. Data Skimming\n",
    "\n",
    "    1-1. Data collect\n",
    "    1-2. Data load\n",
    "    1-3. Data Skimming ( to excel _ )\n",
    "\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "    2-1. Fill NAs\n",
    "    2-2. Drop\n",
    "    2-3. Editing ( Adding, Editing, Binning etc..)\n",
    "    \n",
    "    \n",
    "## 3. Model & Evaluation\n",
    "\n",
    "    3-1 pipeline\n",
    "    3-2 Model Selection & Eval\n",
    "    3-3 Result - Submission\n",
    "    \n",
    "    \n",
    "*******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# install xgboost\\nhttp://cleancode-ws.tistory.com/79\\n# understanding xgboost\\nhttps://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#from xgboost import XGBRegressor\n",
    "# if you want to use XGBoost\n",
    "'''\n",
    "# install xgboost\n",
    "http://cleancode-ws.tistory.com/79\n",
    "# understanding xgboost\n",
    "https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Skimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "full = pd.concat([train,test],ignore_index=True)\n",
    "cols = train.columns\n",
    "nulls = full.isnull().sum()\n",
    "nulls = nulls[nulls>0]\n",
    "nulls_index = nulls.index\n",
    "datacols = []\n",
    "datanull = []\n",
    "datatype = []\n",
    "datavalue = []\n",
    "\n",
    "for col in cols:\n",
    "    datacols += [col]\n",
    "    datatype += [train[col].dtype]\n",
    "    datavalue+= [train[col][0]]\n",
    "    if col in nulls_index :\n",
    "        datanull += [nulls[col]]\n",
    "    else :\n",
    "        datanull += [0]\n",
    "        \n",
    "idd = list(range(cols.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Missing Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! 이 부분이 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이부분이 추가됨 !!!!!!!!!!!\n",
    "cols2 = [\"MSZoning\", \"BsmtFullBath\", \"BsmtHalfBath\", \"Utilities\", \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\"Exterior1st\", \"Exterior2nd\"]\n",
    "for col in cols2:\n",
    "    full[col].fillna(full[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])\n",
    "\n",
    "full['LotAreaCut']= pd.qcut(full.LotArea,10)\n",
    "\n",
    "full['LotFrontage'] = full.groupby(['LotAreaCut','Neighborhood'])['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "\n",
    "# 나머지 변수들은 다 0 이나 None 값으로\n",
    "# nulls_index = nulls.index\n",
    "\n",
    "for col in nulls_index:\n",
    "    na_value = 0\n",
    "    if full[col].dtype == object :\n",
    "        na_value = \"None\"\n",
    "    full[col].fillna(na_value, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. drop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이부분도 하나더 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = ['SalePrice','Id','Utilities']\n",
    "for var in drop_index:\n",
    "    full.drop([var],axis=1,inplace = True)\n",
    "#all_data = all_data.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) type 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_col = full.columns\n",
    "for var in full_col:\n",
    "    if full[var].dtype == object :\n",
    "        full[var] = full[var].astype(str)\n",
    "        \n",
    "time = ['GarageYrBlt','YearBuilt','YearRemodAdd','MoSold','YrSold']\n",
    "categorical = ['MSSubClass','OverallQual','OverallCond',]\n",
    "strtype = time + categorical\n",
    "for var in strtype:\n",
    "    full[var] = full[var].astype(str)\n",
    "    \n",
    "full.drop('LotAreaCut',axis=1,inplace=True)\n",
    "full_col = full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric 변수들 모음\n",
    "numeric_col = []\n",
    "for var in full_col:\n",
    "    if type(full[var][0]) != str:\n",
    "        numeric_col += [var]\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# ~.fit(data), ~.fit_transform()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "standard = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "\n",
    "# 각 scale을 따로 적용하기 위해서 full의 copy version을 만든다.\n",
    "full2 = full.copy()\n",
    "full3 = full.copy()\n",
    "full4 = full.copy()\n",
    "\n",
    "#full1 은 no scale\n",
    "full2[numeric_col] = minmax.fit_transform(full2[numeric_col])\n",
    "full3[numeric_col] = standard.fit_transform(full3[numeric_col])\n",
    "full4[numeric_col] = robust.fit_transform(full4[numeric_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) categorical 변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수 설정\n",
    "def map_values(full):\n",
    "    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n",
    "                                        '30':2, '45':2, \n",
    "                                        '190':3, '50':3, '90':3, \n",
    "                                        '85':4, '40':4, '160':4, \n",
    "                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                        '120': 6, '60':6})\n",
    "    \n",
    "    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n",
    "                                               'IDOTRR':2, 'BrDale':2,\n",
    "                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n",
    "                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n",
    "                                               'NPkVill':5, 'Mitchel':5,\n",
    "                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n",
    "                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n",
    "                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n",
    "                                               'StoneBr':9,\n",
    "                                               'NoRidge':10, 'NridgHt':10})\n",
    "    \n",
    "    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n",
    "    \n",
    "    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n",
    "                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n",
    "                                           '1Story':3, 'SLvl':3,\n",
    "                                           '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n",
    "                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n",
    "                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n",
    "                                             'BrkFace':4, 'Plywood':4,\n",
    "                                             'VinylSd':5,\n",
    "                                             'CemntBd':6,\n",
    "                                             'Stone':7, 'ImStucc':7})\n",
    "    \n",
    "    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n",
    "    \n",
    "    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n",
    "                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n",
    "                                           'Wood':3, 'PConc':4})\n",
    "    \n",
    "    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n",
    "    \n",
    "    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n",
    "    \n",
    "    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n",
    "    \n",
    "    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                           'Detchd':2,\n",
    "                                           '2Types':3, 'Basment':3,\n",
    "                                           'Attchd':4, 'BuiltIn':5})\n",
    "    \n",
    "    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n",
    "    \n",
    "    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n",
    "                                       'CWD':2, 'Con':3, 'New':3})\n",
    "    \n",
    "    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n",
    "                \n",
    "                        \n",
    "                        \n",
    "    \n",
    "    return full\n",
    "\n",
    "full2 = map_values(full2)\n",
    "full3 = map_values(full3)\n",
    "full4 = map_values(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = full2.columns\n",
    "for col in cols:\n",
    "    na_value = 0\n",
    "    full2[col].fillna(na_value, inplace = True)\n",
    "    full3[col].fillna(na_value, inplace = True)\n",
    "    full4[col].fillna(na_value, inplace = True)\n",
    "# mapping 한것들 NA 값들도 넣어주기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = full4.isnull().sum()\n",
    "aa[aa>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cols:\n",
    "    if full4[var].dtype == int :\n",
    "        full2[var] = full2[var].astype(float)\n",
    "        full3[var] = full3[var].astype(float)\n",
    "        full4[var] = full4[var].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string -> one_hot_encoding\n",
    "full2 = pd.get_dummies(full2)\n",
    "full3 = pd.get_dummies(full3)\n",
    "full4 = pd.get_dummies(full4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 649)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 값\n",
    "# label 분리 SalePrice 부분, 그리고 log scale까지\n",
    "y = train['SalePrice']\n",
    "y_log = np.log(y)\n",
    "# x 값들 (columns, features, inputs)\n",
    "n_train = train.shape[0]\n",
    "x2 = full2[:n_train]\n",
    "x3 = full3[:n_train]\n",
    "x4 = full4[:n_train]\n",
    "\n",
    "test_x2 = full2[n_train:]\n",
    "test_x3 = full3[n_train:]\n",
    "test_x4 = full4[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Model & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(alpha=0.01,max_iter=10000),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          SVR(),\n",
    "          LinearSVR(),\n",
    "          ElasticNet(alpha=0.001,max_iter=10000),\n",
    "          SGDRegressor(max_iter=1000,tol=1e-3),\n",
    "          BayesianRidge(),\n",
    "          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),\n",
    "          ]\n",
    "\n",
    "# if you have xgboost package, put XGBRegressor() in models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 2138644557.281348, 1582972367.8413\n",
      "Ridge: 0.154460, 0.0183\n",
      "Lasso: 0.197213, 0.0110\n",
      "RF: 0.155159, 0.0119\n",
      "GBR: 0.131841, 0.0105\n",
      "SVR: 0.156484, 0.0095\n",
      "LinSVR: 0.180876, 0.0314\n",
      "Ela: 0.134774, 0.0146\n",
      "SGD: 0.264571, 0.0261\n",
      "Bay: 0.145354, 0.0137\n",
      "Ker: 0.154582, 0.0087\n",
      "Extra: 0.154161, 0.0113\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x2 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 2158100766.766269, 1335522960.7328\n",
      "Ridge: 0.155642, 0.0218\n",
      "Lasso: 0.160540, 0.0175\n",
      "RF: 0.154231, 0.0092\n",
      "GBR: 0.131064, 0.0103\n",
      "SVR: 0.128668, 0.0104\n",
      "LinSVR: 0.182408, 0.0256\n",
      "Ela: 0.136314, 0.0224\n",
      "SGD: 0.245357, 0.0126\n",
      "Bay: 0.140266, 0.0197\n",
      "Ker: 0.132824, 0.0153\n",
      "Extra: 0.151125, 0.0152\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x3 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 2042551.010324, 2571410.1109\n",
      "Ridge: 0.155599, 0.0218\n",
      "Lasso: 0.162120, 0.0175\n",
      "RF: 0.153828, 0.0090\n",
      "GBR: 0.130606, 0.0102\n",
      "SVR: 0.212487, 0.0169\n",
      "LinSVR: 0.249529, 0.0534\n",
      "Ela: 0.136679, 0.0222\n",
      "SGD: 1029290514788980.375000, 1491317160471708.0000\n",
      "Bay: 0.140354, 0.0195\n",
      "Ker: 0.346096, 0.3425\n",
      "Extra: 0.157652, 0.0116\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, x4 , y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search\n",
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13482498305153187\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.136033        0.005013\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.134927        0.004507\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.134825        0.003929\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.135922        0.003578\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.1374340355848717\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.138767        0.006998\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.137970        0.006894\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.137434        0.006708\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.138098        0.006516\n",
      "{'alpha': 0.0007, 'max_iter': 10000} 0.13764006374092105\n",
      "                                 params  mean_test_score  std_test_score\n",
      "0  {'alpha': 0.0004, 'max_iter': 10000}         0.138992        0.006960\n",
      "1  {'alpha': 0.0005, 'max_iter': 10000}         0.138304        0.006853\n",
      "2  {'alpha': 0.0007, 'max_iter': 10000}         0.137640        0.006631\n",
      "3  {'alpha': 0.0009, 'max_iter': 10000}         0.138370        0.006410\n"
     ]
    }
   ],
   "source": [
    "grid(Lasso()).grid_get(x2,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x3,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})\n",
    "grid(Lasso()).grid_get(x4,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 35} 0.1489272238704992\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.148927        0.002734\n",
      "1  {'alpha': 40}         0.149999        0.002709\n",
      "2  {'alpha': 45}         0.151023        0.002692\n",
      "3  {'alpha': 50}         0.151997        0.002682\n",
      "4  {'alpha': 55}         0.152923        0.002677\n",
      "5  {'alpha': 60}         0.153804        0.002676\n",
      "6  {'alpha': 65}         0.154642        0.002677\n",
      "7  {'alpha': 70}         0.155442        0.002680\n",
      "8  {'alpha': 80}         0.156937        0.002692\n",
      "9  {'alpha': 90}         0.158308        0.002708\n",
      "{'alpha': 35} 0.14102511699164713\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.141025        0.005851\n",
      "1  {'alpha': 40}         0.141033        0.005854\n",
      "2  {'alpha': 45}         0.141084        0.005857\n",
      "3  {'alpha': 50}         0.141163        0.005860\n",
      "4  {'alpha': 55}         0.141262        0.005862\n",
      "5  {'alpha': 60}         0.141373        0.005862\n",
      "6  {'alpha': 65}         0.141492        0.005862\n",
      "7  {'alpha': 70}         0.141617        0.005860\n",
      "8  {'alpha': 80}         0.141877        0.005855\n",
      "9  {'alpha': 90}         0.142140        0.005846\n",
      "{'alpha': 35} 0.1407962973256307\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 35}         0.140796        0.005687\n",
      "1  {'alpha': 40}         0.140809        0.005673\n",
      "2  {'alpha': 45}         0.140867        0.005660\n",
      "3  {'alpha': 50}         0.140956        0.005646\n",
      "4  {'alpha': 55}         0.141065        0.005633\n",
      "5  {'alpha': 60}         0.141189        0.005620\n",
      "6  {'alpha': 65}         0.141322        0.005606\n",
      "7  {'alpha': 70}         0.141463        0.005592\n",
      "8  {'alpha': 80}         0.141756        0.005564\n",
      "9  {'alpha': 90}         0.142055        0.005534\n"
     ]
    }
   ],
   "source": [
    "grid(Ridge()).grid_get(x2,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x3,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})\n",
    "grid(Ridge()).grid_get(x4,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': 10000} 0.1379750247000158\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.147719   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.146353   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.138478   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.138173   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.137975   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.141983   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.138510   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138607   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.145411   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.005444  \n",
      "1        0.005350  \n",
      "2        0.004821  \n",
      "3        0.003372  \n",
      "4        0.003230  \n",
      "5        0.002677  \n",
      "6        0.003091  \n",
      "7        0.002954  \n",
      "8        0.002587  \n",
      "{'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': 10000} 0.13884979910509537\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149587   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148200   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.140476   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.139351   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.139038   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.140389   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.139059   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138850   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.142367   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.006815  \n",
      "1        0.006733  \n",
      "2        0.006459  \n",
      "3        0.006072  \n",
      "4        0.006127  \n",
      "5        0.006445  \n",
      "6        0.006109  \n",
      "7        0.006156  \n",
      "8        0.006549  \n",
      "{'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': 10000} 0.13894671280485343\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.0008, 'l1_ratio': 0.08, 'max_iter'...         0.149582   \n",
      "1  {'alpha': 0.0008, 'l1_ratio': 0.1, 'max_iter':...         0.148199   \n",
      "2  {'alpha': 0.0008, 'l1_ratio': 0.3, 'max_iter':...         0.140555   \n",
      "3  {'alpha': 0.004, 'l1_ratio': 0.08, 'max_iter':...         0.139366   \n",
      "4  {'alpha': 0.004, 'l1_ratio': 0.1, 'max_iter': ...         0.139079   \n",
      "5  {'alpha': 0.004, 'l1_ratio': 0.3, 'max_iter': ...         0.140487   \n",
      "6  {'alpha': 0.005, 'l1_ratio': 0.08, 'max_iter':...         0.139073   \n",
      "7  {'alpha': 0.005, 'l1_ratio': 0.1, 'max_iter': ...         0.138947   \n",
      "8  {'alpha': 0.005, 'l1_ratio': 0.3, 'max_iter': ...         0.142531   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.006804  \n",
      "1        0.006719  \n",
      "2        0.006438  \n",
      "3        0.006013  \n",
      "4        0.006044  \n",
      "5        0.006272  \n",
      "6        0.006020  \n",
      "7        0.006067  \n",
      "8        0.006374  \n"
     ]
    }
   ],
   "source": [
    "grid(ElasticNet()).grid_get(x2,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x3,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})\n",
    "grid(ElasticNet()).grid_get(x4,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.14744413153527589\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.153348   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.147444   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.159793   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.151831   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.165418   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.155720   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.002819  \n",
      "1        0.002639  \n",
      "2        0.003045  \n",
      "3        0.002716  \n",
      "4        0.003281  \n",
      "5        0.002816  \n",
      "{'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kernel': 'polynomial'} 0.12818622683331404\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...         0.134801   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...         0.128186   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...         0.140463   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...         0.131348   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...         0.145797   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...         0.134519   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.002185  \n",
      "1        0.002269  \n",
      "2        0.002167  \n",
      "3        0.002231  \n",
      "4        0.002219  \n",
      "5        0.002236  \n",
      "{'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'kernel': 'polynomial'} 12.355869814577636\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 0.2, 'coef0': 0.8, 'degree': 3, 'ker...        12.355870   \n",
      "1  {'alpha': 0.2, 'coef0': 1, 'degree': 3, 'kerne...        48.054588   \n",
      "2  {'alpha': 0.3, 'coef0': 0.8, 'degree': 3, 'ker...        22.801391   \n",
      "3  {'alpha': 0.3, 'coef0': 1, 'degree': 3, 'kerne...        39.509244   \n",
      "4  {'alpha': 0.4, 'coef0': 0.8, 'degree': 3, 'ker...        32.583286   \n",
      "5  {'alpha': 0.4, 'coef0': 1, 'degree': 3, 'kerne...        30.517721   \n",
      "\n",
      "   std_test_score  \n",
      "0      215.830848  \n",
      "1     4616.045720  \n",
      "2      881.323687  \n",
      "3     3116.121412  \n",
      "4     1904.649350  \n",
      "5     1847.005776  \n"
     ]
    }
   ],
   "source": [
    "param_grid={'alpha':[0.2,0.3,0.4], 'kernel':[\"polynomial\"], 'degree':[3],'coef0':[0.8,1]}\n",
    "grid(KernelRidge()).grid_get(x2,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x3,y_log,param_grid)\n",
    "grid(KernelRidge()).grid_get(x4,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12627993462414\n"
     ]
    }
   ],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "ridge = Ridge(alpha=35)\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()\n",
    "\n",
    "# assign weights based on their gridsearch score\n",
    "w1 = 0.0\n",
    "w2 = 0.0\n",
    "w3 = 0.3\n",
    "w4 = 0.5\n",
    "w5 = 0.2\n",
    "w6 = 0.0\n",
    "\n",
    "weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n",
    "\n",
    "\n",
    "score = rmse_cv(weight_avg,x3,y_log) #커널만 x3쓰기 pred에서 지금이 제일 낮은 item 찾음\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Result - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러모델 평균\n",
    "r1 = lasso.fit(x3,y_log)\n",
    "r2 = ridge.fit(x3,y_log)\n",
    "r3 = svr.fit(x3,y_log)\n",
    "r4 = ker.fit(x3,y_log)\n",
    "r5 = ela.fit(x3,y_log)\n",
    "r6 = bay.fit(x3,y_log)\n",
    "\n",
    "pred_r1 =np.exp(r1.predict(test_x3))\n",
    "pred_r2 =np.exp(r2.predict(test_x3))\n",
    "pred_r3 =np.exp(r3.predict(test_x3))\n",
    "pred_r4 =np.exp(r4.predict(test_x3))\n",
    "pred_r5 =np.exp(r5.predict(test_x3))\n",
    "pred_r6 =np.exp(r6.predict(test_x3))\n",
    "\n",
    "pred_final = w1 * pred_r1 + w2 * pred_r2 + w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 + w6 * pred_r6\n",
    "#pred_final =  w3 * pred_r3 + w4 * pred_r4 + w5 * pred_r5 \n",
    "\n",
    "\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_final})\n",
    "result.to_csv(\"submission7.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47170710-adfa5800-d341-11e8-8063-fe1312148e83.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47187882-c3d34180-d370-11e8-9456-a86cc62615c0.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical 변수 mapping 해서 numeric으로 넣어주니까 스코어는 더 낮아짐.\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188599-ace21e80-d373-11e8-8799-7e0f289dd706.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x2, x3 교차해서 결과내니 성능 더 낮아짐\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47188508-4c52e180-d373-11e8-8d9c-38f3c4b9d910.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가로 해야할 것들, mapping 한 결과들 한 번 다 넣어보기. 그리고 lasso, 다른 결과들이 어떻게 내는지 확인해볼 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47236579-968d9e80-d417-11e8-8aab-9562d439fbe1.PNG\")\n",
    "# 0.01 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/24144491/47237501-43691b00-d41a-11e8-8c44-1ea5e674b9a4.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image(url = \"https://user-images.githubusercontent.com/24144491/47237501-43691b00-d41a-11e8-8c44-1ea5e674b9a4.PNG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skew-processing is All you need\n",
    "# 참고 url : https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box Cox Transformation of (highly) skewed features\n",
    "\n",
    "We use the scipy function boxcox1p which computes the Box-Cox transformation of  1+x .\n",
    "\n",
    "Note that setting  λ=0  is equivalent to log1p used above for the target variable.\n",
    "\n",
    "See this page for more details on Box Cox Transformation as well as the scipy function's page\n",
    "\n",
    "http://onlinestatbook.com/2/transformations/box-cox.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
